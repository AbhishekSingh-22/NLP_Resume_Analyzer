{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2acda504",
   "metadata": {},
   "source": [
    "1. Import all required modules for src/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e323d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported pipeline helpers from src/\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "# If notebooks/ is the cwd (typical), add repo root to sys.path\n",
    "repo_root = Path(\"..\").resolve()\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "\n",
    "# Now import our modules\n",
    "from src.pipeline import process_pdf_bytes\n",
    "from src.extract import extract_text_from_pdf_bytes, sniff_is_text_pdf\n",
    "from src.parse import parse_basic_fields\n",
    "from src.score import enriched_score\n",
    "from src.summarize import summarize_with_model\n",
    "from src.review import generate_review_from_summary\n",
    "from src.io import save_json, load_json\n",
    "\n",
    "print(\"Imported pipeline helpers from src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15c51d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patched D:\\Work\\Capstone_Project\\resume-nlp\\src\\score.py\n",
      "Reloaded src.score\n",
      "Reloaded src.pipeline\n",
      "Processing: Abhishek_Singh_Resume.pdf\n",
      "{'emails': ['abhisheksingh.vizag@gmail.com'],\n",
      " 'parsed_keys': ['primary_name',\n",
      "                 'emails',\n",
      "                 'phones',\n",
      "                 'skills',\n",
      "                 'orgs',\n",
      "                 'preview',\n",
      "                 'education',\n",
      "                 'resume_id'],\n",
      " 'phones': ['8010852459'],\n",
      " 'score': {'reasons': {'has_contact': True, 'n_skills': 5}, 'score': 60.0},\n",
      " 'short_review': 'Detected skills: python, c++, sql, docker, git.',\n",
      " 'skills': ['python', 'c++', 'sql', 'docker', 'git'],\n",
      " 'summary_preview': 'Abhishek Singh — 5 skills detected: python, c++, sql, '\n",
      "                    'docker, git.'}\n"
     ]
    }
   ],
   "source": [
    "# Patch src/score.py to make enriched_score accept optional summary, reload modules, and re-run smoke test.\n",
    "from pathlib import Path\n",
    "import importlib, sys, traceback\n",
    "\n",
    "repo_root = Path(\"..\").resolve()\n",
    "src_dir = repo_root / \"src\"\n",
    "score_path = src_dir / \"score.py\"\n",
    "assert score_path.exists(), f\"Expected {score_path} to exist\"\n",
    "\n",
    "# === 1) Overwrite src/score.py with corrected content ===\n",
    "score_code = r'''\n",
    "from typing import Dict, Any\n",
    "\n",
    "def baseline_score(parsed: Dict[str, Any]) -> float:\n",
    "    \"\"\"\n",
    "    Simple baseline score combining:\n",
    "      - presence of contact\n",
    "      - number of skills (capped)\n",
    "      - character count (proxy for content)\n",
    "    Returns score in 0-100 (not calibrated).\n",
    "    \"\"\"\n",
    "    score = 0.0\n",
    "    has_contact = bool(parsed.get(\"emails\") or parsed.get(\"phones\"))\n",
    "    score += 30.0 if has_contact else 0.0\n",
    "    n_skills = len(parsed.get(\"skills\", []))\n",
    "    score += min(n_skills, 10) * 5.0   # up to 50 points\n",
    "    chars = len(parsed.get(\"preview\",\"\"))\n",
    "    if chars > 4000:\n",
    "        score += 20.0\n",
    "    elif chars > 2000:\n",
    "        score += 10.0\n",
    "    elif chars > 800:\n",
    "        score += 5.0\n",
    "    return round(min(100.0, score), 3)\n",
    "\n",
    "def enriched_score(parsed: Dict[str, Any], summary: Dict[str, Any]=None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Compute base score and return a dict with details.\n",
    "    The `summary` argument is optional to support callers that pass it or not.\n",
    "    \"\"\"\n",
    "    base = baseline_score(parsed)\n",
    "    return {\"score\": base, \"reasons\": {\"has_contact\": bool(parsed.get(\"emails\") or parsed.get(\"phones\")), \"n_skills\": len(parsed.get(\"skills\",[]))}}\n",
    "'''\n",
    "score_path.write_text(score_code, encoding=\"utf-8\")\n",
    "print(f\"Patched {score_path}\")\n",
    "\n",
    "# === 2) Reload modules so changes are visible in this running kernel ===\n",
    "# ensure repo root is on sys.path\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "\n",
    "try:\n",
    "    import src.score as score_mod\n",
    "    importlib.reload(score_mod)\n",
    "    print(\"Reloaded src.score\")\n",
    "except Exception:\n",
    "    traceback.print_exc()\n",
    "\n",
    "try:\n",
    "    import src.pipeline as pipeline_mod\n",
    "    importlib.reload(pipeline_mod)\n",
    "    print(\"Reloaded src.pipeline\")\n",
    "except Exception:\n",
    "    traceback.print_exc()\n",
    "\n",
    "# === 3) Re-run the same smoke test you ran before (adjust path if necessary) ===\n",
    "from pathlib import Path\n",
    "sample_pdf = Path(\"../data/resumes_preocr/pdfs/sample_00001.pdf\")\n",
    "if not sample_pdf.exists():\n",
    "    candidates = list(sample_pdf.parent.glob(\"*.pdf\")) if sample_pdf.parent.exists() else []\n",
    "    if candidates:\n",
    "        sample_pdf = candidates[0]\n",
    "    else:\n",
    "        raise FileNotFoundError(\"No sample PDF found at ../data/resumes_preocr/pdfs/*.pdf\")\n",
    "\n",
    "pdf_bytes = sample_pdf.read_bytes()\n",
    "print(\"Processing:\", sample_pdf.name)\n",
    "out = pipeline_mod.process_pdf_bytes(pdf_bytes, resume_id=sample_pdf.name, model_fn=None)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint({\n",
    "    \"parsed_keys\": list(out[\"parsed\"].keys()),\n",
    "    \"emails\": out[\"parsed\"].get(\"emails\"),\n",
    "    \"phones\": out[\"parsed\"].get(\"phones\"),\n",
    "    \"skills\": out[\"parsed\"].get(\"skills\"),\n",
    "    \"score\": out[\"score\"],\n",
    "    \"summary_preview\": out[\"summary\"][\"summary\"][:300],\n",
    "    \"short_review\": out[\"review\"][\"short_review\"][:300]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bc623ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Abhishek_Singh_Resume.pdf\n",
      "{'emails': ['abhisheksingh.vizag@gmail.com'],\n",
      " 'parsed_keys': ['primary_name',\n",
      "                 'emails',\n",
      "                 'phones',\n",
      "                 'skills',\n",
      "                 'orgs',\n",
      "                 'preview',\n",
      "                 'education',\n",
      "                 'resume_id'],\n",
      " 'phones': ['8010852459'],\n",
      " 'score': {'reasons': {'has_contact': True, 'n_skills': 5}, 'score': 60.0},\n",
      " 'short_review': 'Detected skills: python, c++, sql, docker, git.',\n",
      " 'skills': ['python', 'c++', 'sql', 'docker', 'git'],\n",
      " 'summary_preview': 'Abhishek Singh — 5 skills detected: python, c++, sql, '\n",
      "                    'docker, git.'}\n"
     ]
    }
   ],
   "source": [
    "# Cell C: smoke test — process a single PDF using the new pipeline\n",
    "from pathlib import Path\n",
    "sample_pdf = Path(\"../data/resumes_preocr/pdfs/Abhishek_Singh_Resume.pdf\")\n",
    "if not sample_pdf.exists():\n",
    "    # attempt to find any pdf in that folder\n",
    "    candidates = list(sample_pdf.parent.glob(\"*.pdf\")) if sample_pdf.parent.exists() else []\n",
    "    if candidates:\n",
    "        sample_pdf = candidates[0]\n",
    "    else:\n",
    "        raise FileNotFoundError(\"No sample PDF found. Put a sample PDF at ../data/resumes_preocr/pdfs/ or update path.\")\n",
    "\n",
    "pdf_bytes = sample_pdf.read_bytes()\n",
    "print(\"Processing:\", sample_pdf.name)\n",
    "out = process_pdf_bytes(pdf_bytes, resume_id=sample_pdf.name, model_fn=None)   # model_fn=None => rule-based summary\n",
    "# quick examine\n",
    "from pprint import pprint\n",
    "pprint({\n",
    "    \"parsed_keys\": list(out[\"parsed\"].keys()),\n",
    "    \"emails\": out[\"parsed\"].get(\"emails\"),\n",
    "    \"phones\": out[\"parsed\"].get(\"phones\"),\n",
    "    \"skills\": out[\"parsed\"].get(\"skills\"),\n",
    "    \"score\": out[\"score\"],\n",
    "    \"summary_preview\": out[\"summary\"][\"summary\"][:300],\n",
    "    \"short_review\": out[\"review\"][\"short_review\"][:300]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68d6673e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Abhishek_Singh_Resume.pdf -> {'file': 'Abhishek_Singh_Resume.pdf', 'ok': True, 'score': 60.0}\n",
      "Done. Saved per-resume JSON to ..\\data\\resumes_preocr\\modular_outputs\n"
     ]
    }
   ],
   "source": [
    "# Cell D: process N resumes (modular pipeline) and save outputs\n",
    "from pathlib import Path\n",
    "DATA_DIR = Path(\"../data/resumes_preocr\")\n",
    "PDF_DIR = DATA_DIR / \"pdfs\"\n",
    "OUT_DIR = DATA_DIR / \"modular_outputs\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pdf_paths = sorted(PDF_DIR.glob(\"*.pdf\"))\n",
    "N = 20   # change to smaller first (e.g., 20) to test; set to len(pdf_paths) to run all\n",
    "pdf_paths = pdf_paths[:N]\n",
    "\n",
    "results = []\n",
    "for p in pdf_paths:\n",
    "    try:\n",
    "        b = p.read_bytes()\n",
    "        res = process_pdf_bytes(b, resume_id=p.name, model_fn=None)\n",
    "        save_json(res, OUT_DIR / (p.stem + \".json\"))\n",
    "        results.append({\"file\": p.name, \"ok\": True, \"score\": res[\"score\"][\"score\"]})\n",
    "    except Exception as e:\n",
    "        results.append({\"file\": p.name, \"ok\": False, \"error\": str(e)})\n",
    "    print(f\"Processed {p.name} -> {results[-1]}\")\n",
    "print(\"Done. Saved per-resume JSON to\", OUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
